{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\n\nfrom tqdm.notebook import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-12-19T16:47:13.655951Z","iopub.execute_input":"2022-12-19T16:47:13.656646Z","iopub.status.idle":"2022-12-19T16:47:15.904045Z","shell.execute_reply.started":"2022-12-19T16:47:13.656554Z","shell.execute_reply":"2022-12-19T16:47:15.903087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"导入数据","metadata":{}},{"cell_type":"code","source":"DATA_DIR = os.path.join(\"/kaggle\", \"input\", \"semantic-segmentation\", \"semantic-segmentation\",\"data\")\nclass_dict = pd.read_csv(os.path.join(DATA_DIR, 'labels_class_dict.csv'))\n# Get class names\nclass_names = class_dict['class_names'].tolist()\n# Get class RGB values\nclass_rgb_values = class_dict[['r', 'g', 'b']].values.tolist()\nprint('All dataset classes and their corresponding RGB values in labels:')\nprint('Class Names: ', class_names)\nprint('Class RGB values: ', class_rgb_values)","metadata":{"execution":{"iopub.status.busy":"2022-12-19T16:47:15.909447Z","iopub.execute_input":"2022-12-19T16:47:15.911411Z","iopub.status.idle":"2022-12-19T16:47:15.965393Z","shell.execute_reply.started":"2022-12-19T16:47:15.911359Z","shell.execute_reply":"2022-12-19T16:47:15.964061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_names = os.listdir(os.path.join(DATA_DIR, 'images'))\nimage_paths = [os.path.join(DATA_DIR, 'images', image_name) for image_name in image_names]\nmask_paths = [os.path.join(DATA_DIR, 'masks', image_name.replace('jpg', 'png')) for image_name in image_names]\n\n#把颜色格式转化成rgb\nimages = [cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB) for image_path in image_paths]\nmasks = [cv2.cvtColor(cv2.imread(mask_path), cv2.COLOR_BGR2RGB) for mask_path in mask_paths]\nprint(len(images),len(masks))\n# mask = cv2.cvtColor(cv2.imread(mask_paths[0]), cv2.COLOR_BGR2RGB)\n\nimages = [cv2.resize(image,(320,320)) for image in images]\nmasks = [cv2.resize(mask,(320,320)) for mask in masks]\n\n#打印样本图片\nfig, axes = plt.subplots(1, 2, figsize=(10, 5))\naxes[0].imshow(images[1])\naxes[1].imshow(masks[1])","metadata":{"execution":{"iopub.status.busy":"2022-12-19T16:47:15.967008Z","iopub.execute_input":"2022-12-19T16:47:15.967733Z","iopub.status.idle":"2022-12-19T16:47:32.255544Z","shell.execute_reply.started":"2022-12-19T16:47:15.967685Z","shell.execute_reply":"2022-12-19T16:47:32.254306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"图片预处理\n\none-hot :https://blog.csdn.net/baidu_36511315/article/details/105528546","metadata":{}},{"cell_type":"code","source":"def one_hot_encode(label, label_values):\n    \"\"\"\n    Convert a segmentation image label array to one-hot format\n    by replacing each pixel value with a vector of length num_classes\n    # Arguments\n        label: The 2D array segmentation image label\n        label_values\n\n    # Returns\n        A 2D array with the same width and height as the input, but\n        with a depth size of num_classes\n    \"\"\"\n    semantic_map = []\n    for colour in label_values:\n        equality = np.equal(label, colour)\n        class_map = np.all(equality, axis=-1)\n        semantic_map.append(class_map)\n    semantic_map = np.stack(semantic_map, axis=-1)\n\n    return semantic_map\n\n# Perform reverse one-hot-encoding on labels / preds\n\n\ndef reverse_one_hot(image):\n    \"\"\"\n    Transform a 2D array in one-hot format (depth is num_classes),\n    to a 2D array with only 1 channel, where each pixel value is\n    the classified class key.\n    # Arguments\n        image: The one-hot format image \n\n    # Returns\n        A 2D array with the same width and height as the input, but\n        with a depth size of 1, where each pixel value is the classified \n        class key.\n    \"\"\"\n    x = np.argmax(image, axis=-1)\n    return x","metadata":{"execution":{"iopub.status.busy":"2022-12-19T16:47:32.258915Z","iopub.execute_input":"2022-12-19T16:47:32.260147Z","iopub.status.idle":"2022-12-19T16:47:32.269946Z","shell.execute_reply.started":"2022-12-19T16:47:32.260096Z","shell.execute_reply":"2022-12-19T16:47:32.268973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"masks = [one_hot_encode(mask, class_rgb_values).astype('float') for mask in masks]\nprint('Image shape: ', images[0].shape)\nprint('Mask shape: ', masks[0].shape)\n\n# masks = [reverse_one_hot(mask) for mask in masks]\n# print(masks[0].shape)","metadata":{"execution":{"iopub.status.busy":"2022-12-19T16:47:32.271223Z","iopub.execute_input":"2022-12-19T16:47:32.272303Z","iopub.status.idle":"2022-12-19T16:48:01.629454Z","shell.execute_reply.started":"2022-12-19T16:47:32.272267Z","shell.execute_reply":"2022-12-19T16:48:01.628046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"分割数据集（前100为训练数据，后615为测试数据）","metadata":{}},{"cell_type":"code","source":"train_image = images[:50]\ntest_image = images[50:]\nprint(len(train_image),len(test_image))\ntrain_mask = masks[:50]\ntest_mask = masks[50:]\nprint(len(train_mask),len(test_mask))\n\n# #打印样本图片\n# fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n# axes[0].imshow(test_image[1])\n# axes[1].imshow(test_mask[1])\n\n# for i in range(100):\n#     print(train_image[i].shape,train_mask[i].shape)\n# test = train_image[i].reshape(240,-1)\n# print(test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-12-19T16:48:01.630642Z","iopub.execute_input":"2022-12-19T16:48:01.630956Z","iopub.status.idle":"2022-12-19T16:48:01.637624Z","shell.execute_reply.started":"2022-12-19T16:48:01.630929Z","shell.execute_reply":"2022-12-19T16:48:01.636378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"定义dataset","metadata":{}},{"cell_type":"code","source":"class imageDataset(Dataset):\n    def __init__(self,images,masks):\n        self.images = images\n        self.masks = masks\n    def __len__(self):\n        return len(self.images)\n    def __getitem__(self, index):\n        image = np.array(self.images[index])\n        mask = np.array(self.masks[index])\n        transform = transforms.ToTensor()\n        image = transform(image)\n        mask = transform(mask)\n        return image,mask","metadata":{"execution":{"iopub.status.busy":"2022-12-19T16:48:01.639214Z","iopub.execute_input":"2022-12-19T16:48:01.639552Z","iopub.status.idle":"2022-12-19T16:48:01.648774Z","shell.execute_reply.started":"2022-12-19T16:48:01.639507Z","shell.execute_reply":"2022-12-19T16:48:01.647920Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = imageDataset(train_image,train_mask)\nimage,mask = dataset[0]\n# plt.imshow(image)\n# print(image)\nprint(image.shape,mask.shape)","metadata":{"execution":{"iopub.status.busy":"2022-12-19T16:48:01.650057Z","iopub.execute_input":"2022-12-19T16:48:01.651187Z","iopub.status.idle":"2022-12-19T16:48:01.672144Z","shell.execute_reply.started":"2022-12-19T16:48:01.651153Z","shell.execute_reply":"2022-12-19T16:48:01.671135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"UNET模型\n选择原因：cnn二维模型有UNet、ResNet（网络结构过于深，超过1000层）和FCN\nUNET和FCN区别：https://blog.csdn.net/weixin_41108334/article/details/87917748","metadata":{}},{"cell_type":"code","source":"class UNet(nn.Module):\n    \n    def __init__(self, num_classes):\n        super(UNet, self).__init__()\n        self.num_classes = num_classes\n        self.contracting_11 = self.conv_block(in_channels=3, out_channels=64)\n        self.contracting_12 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.contracting_21 = self.conv_block(in_channels=64, out_channels=128)\n        self.contracting_22 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.contracting_31 = self.conv_block(in_channels=128, out_channels=256)\n        self.contracting_32 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.contracting_41 = self.conv_block(in_channels=256, out_channels=512)\n        self.contracting_42 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.middle = self.conv_block(in_channels=512, out_channels=1024)\n        self.expansive_11 = nn.ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=3, stride=2, padding=1, output_padding=1)\n        self.expansive_12 = self.conv_block(in_channels=1024, out_channels=512)\n        self.expansive_21 = nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=3, stride=2, padding=1, output_padding=1)\n        self.expansive_22 = self.conv_block(in_channels=512, out_channels=256)\n        self.expansive_31 = nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=3, stride=2, padding=1, output_padding=1)\n        self.expansive_32 = self.conv_block(in_channels=256, out_channels=128)\n        self.expansive_41 = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=3, stride=2, padding=1, output_padding=1)\n        self.expansive_42 = self.conv_block(in_channels=128, out_channels=64)\n        self.output = nn.Conv2d(in_channels=64, out_channels=num_classes, kernel_size=3, stride=1, padding=1)\n        \n    def conv_block(self, in_channels, out_channels):\n        block = nn.Sequential(nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1),\n                                    nn.ReLU(),\n                                    nn.BatchNorm2d(num_features=out_channels),\n                                    nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1),\n                                    nn.ReLU(),\n                                    nn.BatchNorm2d(num_features=out_channels))\n        return block\n    \n    def forward(self, X):\n        contracting_11_out = self.contracting_11(X) # [-1, 64, 256, 256]\n        contracting_12_out = self.contracting_12(contracting_11_out) # [-1, 64, 128, 128]\n        contracting_21_out = self.contracting_21(contracting_12_out) # [-1, 128, 128, 128]\n        contracting_22_out = self.contracting_22(contracting_21_out) # [-1, 128, 64, 64]\n        contracting_31_out = self.contracting_31(contracting_22_out) # [-1, 256, 64, 64]\n        contracting_32_out = self.contracting_32(contracting_31_out) # [-1, 256, 32, 32]\n        contracting_41_out = self.contracting_41(contracting_32_out) # [-1, 512, 32, 32]\n        contracting_42_out = self.contracting_42(contracting_41_out) # [-1, 512, 16, 16]\n        middle_out = self.middle(contracting_42_out) # [-1, 1024, 16, 16]\n        expansive_11_out = self.expansive_11(middle_out) # [-1, 512, 32, 32]\n        expansive_12_out = self.expansive_12(torch.cat((expansive_11_out, contracting_41_out), dim=1)) # [-1, 1024, 32, 32] -> [-1, 512, 32, 32]\n        expansive_21_out = self.expansive_21(expansive_12_out) # [-1, 256, 64, 64]\n        expansive_22_out = self.expansive_22(torch.cat((expansive_21_out, contracting_31_out), dim=1)) # [-1, 512, 64, 64] -> [-1, 256, 64, 64]\n        expansive_31_out = self.expansive_31(expansive_22_out) # [-1, 128, 128, 128]\n        expansive_32_out = self.expansive_32(torch.cat((expansive_31_out, contracting_21_out), dim=1)) # [-1, 256, 128, 128] -> [-1, 128, 128, 128]\n        expansive_41_out = self.expansive_41(expansive_32_out) # [-1, 64, 256, 256]\n        expansive_42_out = self.expansive_42(torch.cat((expansive_41_out, contracting_11_out), dim=1)) # [-1, 128, 256, 256] -> [-1, 64, 256, 256]\n        output_out = self.output(expansive_42_out) # [-1, num_classes, 256, 256]\n        return output_out\n","metadata":{"execution":{"iopub.status.busy":"2022-12-19T16:48:01.673914Z","iopub.execute_input":"2022-12-19T16:48:01.674582Z","iopub.status.idle":"2022-12-19T16:48:01.695626Z","shell.execute_reply.started":"2022-12-19T16:48:01.674548Z","shell.execute_reply":"2022-12-19T16:48:01.694381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"模型训练","metadata":{}},{"cell_type":"code","source":"batch_size = 16\nepochs = 10\nlr = 0.01\nnum_classes = 9 #label的数量","metadata":{"execution":{"iopub.status.busy":"2022-12-19T16:48:01.699845Z","iopub.execute_input":"2022-12-19T16:48:01.700769Z","iopub.status.idle":"2022-12-19T16:48:01.711293Z","shell.execute_reply.started":"2022-12-19T16:48:01.700730Z","shell.execute_reply":"2022-12-19T16:48:01.709654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = imageDataset(train_image, train_mask)\ndata_loader = DataLoader(dataset, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-12-19T16:48:01.713735Z","iopub.execute_input":"2022-12-19T16:48:01.714230Z","iopub.status.idle":"2022-12-19T16:48:01.723792Z","shell.execute_reply.started":"2022-12-19T16:48:01.714189Z","shell.execute_reply":"2022-12-19T16:48:01.722822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = UNet(num_classes=num_classes)","metadata":{"execution":{"iopub.status.busy":"2022-12-19T16:48:01.725611Z","iopub.execute_input":"2022-12-19T16:48:01.726066Z","iopub.status.idle":"2022-12-19T16:48:01.984664Z","shell.execute_reply.started":"2022-12-19T16:48:01.726023Z","shell.execute_reply":"2022-12-19T16:48:01.983637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=lr)","metadata":{"execution":{"iopub.status.busy":"2022-12-19T16:48:01.986278Z","iopub.execute_input":"2022-12-19T16:48:01.986925Z","iopub.status.idle":"2022-12-19T16:48:01.992872Z","shell.execute_reply.started":"2022-12-19T16:48:01.986889Z","shell.execute_reply":"2022-12-19T16:48:01.991534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"step_losses = []\nepoch_losses = []\nfor epoch in tqdm(range(epochs)):\n    epoch_loss = 0\n    for X, Y in tqdm(data_loader, total=len(data_loader), leave=False):\n        optimizer.zero_grad()\n#         print(X.shape)\n        Y_pred = model(X)\n        loss = criterion(Y_pred, Y)\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item()\n        step_losses.append(loss.item())\n    epoch_losses.append(epoch_loss/len(data_loader))","metadata":{"execution":{"iopub.status.busy":"2022-12-19T16:48:01.994558Z","iopub.execute_input":"2022-12-19T16:48:01.995503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, figsize=(10, 5))\naxes[0].plot(step_losses)\naxes[1].plot(epoch_losses)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = \"U-Net.pth\"\ntorch.save(model.state_dict(), model_name)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"检查模型","metadata":{}},{"cell_type":"code","source":"model_path = \"/kaggle/working/U-Net.pth\"\nmodel_ = UNet(num_classes=num_classes)\nmodel_.load_state_dict(torch.load(model_path))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_batch_size = 8\n# test_i = test_image[:1]\n# test_m = test_mask[:1]\ndataset = imageDataset(test_image, test_mask)\ndata_loader = DataLoader(dataset, batch_size=test_batch_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X, Y = next(iter(data_loader))\nY_pred = model_(X)\nprint(Y_pred.shape)\nY_pred = torch.argmax(Y_pred, dim=1)\nprint(Y_pred.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(test_batch_size, 3, figsize=(3*5, test_batch_size*5))\n\nfor i in range(test_batch_size):\n    \n    landscape = X[i].permute(1, 2, 0).cpu().detach().numpy()\n    label_class = reverse_one_hot(Y[i].permute(1, 2, 0)).cpu().detach().numpy()\n    label_class_predicted = Y_pred[i].cpu().detach().numpy()\n    \n    axes[i, 0].imshow(landscape)\n    axes[i, 0].set_title(\"Landscape\")\n    axes[i, 1].imshow(label_class)\n    axes[i, 1].set_title(\"Label Class\")\n    axes[i, 2].imshow(label_class_predicted)\n    axes[i, 2].set_title(\"Label Class - Predicted\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"计算miou\nhttps://zhuanlan.zhihu.com/p/406706860","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}